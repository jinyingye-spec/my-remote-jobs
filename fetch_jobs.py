import feedparser
import datetime
import re
import pandas as pd
import os

# 1. é…ç½®ä½ è¦æ±‚çš„å…¨éƒ¨æ•°æ®æº
SOURCES = {
    "We Work Remotely": "https://weworkremotely.com/remote-jobs.rss",
    "Working Nomads": "https://www.workingnomads.com/jobsfeed",
    "DailyRemote": "https://dailyremote.com/remote-jobs.rss",
    "JustRemote": "https://justremote.co/remote-jobs.rss",
    # è‡ªç”±èŒä¸šå¹³å°é€šè¿‡ RSS èšåˆæºæ¥å…¥ï¼ˆæ¨¡æ‹ŸæŠ“å–é¡¹ç›®ç±»ï¼‰
    "Upwork (Global)": "https://www.upwork.com/ab/feed/jobs/rss?q=remote",
    "Freelancer (Projects)": "https://www.freelancer.com/rss.xml"
}

def clean_text(text):
    return re.sub('<[^<]+?>', '', text)

def fetch_and_save():
    # è·å–å½“å‰æ—¥æœŸç”¨äº Sheet å‘½å
    now = datetime.datetime.now() + datetime.timedelta(hours=8)
    sheet_name = now.strftime('%Y-%m-%d')
    excel_file = "remote_jobs_list.xlsx"
    
    final_data = []

    for name, url in SOURCES.items():
        print(f"æ­£åœ¨æŠ“å–: {name}...")
        feed = feedparser.parse(url)
        
        count = 0
        for entry in feed.entries:
            if count >= 10: # æ¯ä¸ªå¹³å°æœ€å¤šå– 10 ä¸ªï¼Œç¬¦åˆä½ çš„è¦æ±‚
                break
                
            title = entry.title
            desc = clean_text(entry.summary) if 'summary' in entry else ""
            link = entry.link
            
            # --- ä¼˜å…ˆçº§é€»è¾‘ ---
            # 1. ä¼˜å…ˆæ ‡è®° Anywhere / Worldwide / China
            location = "Remote / Not Specified"
            priority = "Normal"
            
            location_keywords = ["anywhere", "worldwide", "china", "global", "no office"]
            if any(word in (title + desc).lower() for word in location_keywords):
                location = "ğŸŒ Global/Anywhere"
                priority = "â­ High (Remote-First)"
            
            # 2. æå–è–ªèµ„/è®¡è´¹ï¼ˆé’ˆå¯¹ Upwork ç­‰ï¼‰
            salary = "See Link"
            # åŒ¹é… $xx/hr æˆ– $xxx å›ºå®šä»·æ ¼
            salary_match = re.search(r'\$\d+(?:k|/hr| - \$\d+)?', desc + title)
            if salary_match:
                salary = salary_match.group()

            final_data.append({
                "å¹³å°": name,
                "ä¼˜å…ˆçº§": priority,
                "èŒä½åç§°": title,
                "åœ°ç‚¹/é™åˆ¶": location,
                "è–ªèµ„/è®¡è´¹": salary,
                "å‘å¸ƒæ—¶é—´": entry.published[:16] if 'published' in entry else "N/A",
                "ç”³è¯·é“¾æ¥": link
            })
            count += 1

    new_df = pd.DataFrame(final_data)

    # 3. å†™å…¥ Excel (æ–°å¼€ Sheet)
    if os.path.exists(excel_file):
        with pd.ExcelWriter(excel_file, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:
            new_df.to_excel(writer, sheet_name=sheet_name, index=False)
    else:
        new_df.to_excel(excel_file, sheet_name=sheet_name, index=False)

    # 4. æ›´æ–° README é¢„è§ˆ
    content = f"# ğŸŒ å…¨çƒè¿œç¨‹/é¡¹ç›®åˆ¶èŒä½æ±‡æ€»\n\n"
    content += f"> ğŸ¤– è‡ªåŠ¨æ›´æ–°æ—¶é—´: `{now.strftime('%Y-%m-%d %H:%M:%S')}`\n\n"
    content += f"ğŸ“Š **[ç‚¹æ­¤ä¸‹è½½æœ€æ–° Excel è¡¨æ ¼ (å«å†å²åˆ†è¡¨)](./{excel_file})**\n\n"
    
    # é¢„è§ˆé«˜ä¼˜å…ˆçº§èŒä½
    content += "### ğŸš€ ä¼˜å…ˆæ¨è (Anywhere/Global)\n\n"
    content += "| å¹³å° | èŒä½åç§° | è–ªèµ„/è®¡è´¹ | é“¾æ¥ |\n| :--- | :--- | :--- | :--- |\n"
    
    high_priority = [j for j in final_data if j['ä¼˜å…ˆçº§'] == "â­ High (Remote-First)"]
    for job in high_priority[:15]:
        content += f"| {job['å¹³å°']} | {job['èŒä½åç§°']} | {job['è–ªèµ„/è®¡è´¹']} | [ç«‹å³æŸ¥çœ‹]({job['ç”³è¯·é“¾æ¥']}) |\n"

    with open("README.md", "w", encoding="utf-8") as f:
        f.write(content)

if __name__ == "__main__":
    fetch_and_save()
