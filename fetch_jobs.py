import requests
from bs4 import BeautifulSoup
import pandas as pd
from datetime import datetime
import os, re, time

HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'}

def scrape_remote_ok():
    try:
        res = requests.get("https://remoteok.com/api", headers=HEADERS, timeout=15)
        # ä¸¥æ ¼é™åˆ¶ï¼šåªå–å‰ 10 æ¡
        data = res.json()[1:11] 
        return [{"èŒä½": j.get('position'), "å…¬å¸": j.get('company'), "æ¥æº": "RemoteOK", "é“¾æ¥": j.get('url')} for j in data]
    except: return []

def scrape_wwr():
    try:
        res = requests.get("https://weworkremotely.com/remote-jobs.rss", timeout=15)
        # ä½¿ç”¨ lxml è§£æï¼Œç¡®ä¿ä½ åœ¨ main.yml é‡ŒåŠ äº† lxml
        soup = BeautifulSoup(res.text, 'xml')
        items = soup.find_all('item')[:10]
        return [{"èŒä½": i.title.text, "å…¬å¸": "WWR", "æ¥æº": "WWR", "é“¾æ¥": i.link.text} for i in items]
    except: return []

def save_and_update(all_jobs):
    if not all_jobs: return
    
    # æ±‡æ€»å¹¶å†æ¬¡å¼ºåˆ¶æˆªæ–­æ€»æ•°
    df = pd.DataFrame(all_jobs[:30])[["èŒä½", "å…¬å¸", "æ¥æº", "é“¾æ¥"]]
    today = datetime.now().strftime("%Y-%m-%d")
    md_table = df.to_markdown(index=False)
    
    start_tag, end_tag = "", ""
    new_block = f"{start_tag}\n\n### ğŸ“… æ›´æ–°æ—¶é—´: {today}\n\n{md_table}\n\n{end_tag}"

    if os.path.exists("README.md"):
        with open("README.md", "r", encoding="utf-8") as f:
            content = f.read()
        
        # æ ¸å¿ƒä¿®å¤ï¼šå¦‚æœå‘ç°æœ‰å¤šä¸ªé‡å¤æ ‡ç­¾æˆ–åŒ¹é…å¤±è´¥ï¼Œç›´æ¥é‡æ„å†…å®¹
        pattern = re.compile(f"{re.escape(start_tag)}.*?{re.escape(end_tag)}", re.DOTALL)
        
        if start_tag in content and end_tag in content:
            # æ­£å¸¸æ›¿æ¢ï¼šæŠŠæ—§çš„æ‰€æœ‰å†…å®¹ï¼ˆä¸ç®¡å‡ ç™¾è¡Œï¼‰å…¨éƒ¨æŠ¹æ‰
            updated_content = pattern.sub(new_block, content)
        else:
            # å…œåº•ï¼šå¦‚æœæ ‡ç­¾åäº†ï¼Œç›´æ¥é‡å†™æ•´ä¸ª README
            updated_content = f"# è¿œç¨‹èŒä½ç›‘æ§\n\n{new_block}"
            
        with open("README.md", "w", encoding="utf-8") as f:
            f.write(updated_content)
    
    # åŒæ—¶æ›´æ–° Excel å¤‡ä»½
    df.to_excel("remote_jobs_list.xlsx", index=False)
    print(f"âœ… æˆåŠŸæ¸…ç†å¹¶æ›´æ–°äº† {len(df)} æ¡èŒä½")

if __name__ == "__main__":
    data = scrape_wwr() + scrape_remote_ok()
    save_and_update(data)
